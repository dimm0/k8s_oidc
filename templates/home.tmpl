{{define "body"}}
  {{if not .User.Name}}
  <div class="container">
      <div class="jumbotron">
          <div class="text-center">
              <h1 class="mt-5">Welcome to the PRP Kubernetes gateway</h1>
          </div>
      </div>
  </div>
  {{end}}
  {{if .User.Name}}
  <div class="container">
      <div class="jumbotron">
        <div class="container">
          <div class="jumbotron">
            <h3>Slack support channel</h3>
            <p><a href="https://prp-chat.slack.com">https://prp-chat.slack.com</a></p>

            <h3>PRP Kubernetes quick start</h3>
            <p>On first login you get a guest account, which should be verified by admins. You can also ask in Slack chat above.</p>
            <ol>
            <li><a href="https://kubernetes.io/docs/tasks/tools/install-kubectl/">Install</a> the kubectl tool</li>
            <li>Click the "Get Config" link on top and get your config file</li>
              <li>Put the file to your &lt;home&gt;/.kube folder</li>
              <li>Test kubectl can connect to the cluster: <code>kubectl get pods</code>. It's possible there are no pods in your namespace yet.</li>
              <li>Run busybox container in your namespace: <code>kubectl run busybox -it --rm --image=busybox -- sh</code>. It will quit once you log out from the console.</li>
              <li><a href="https://kubernetes.io/docs/tutorials/kubernetes-basics/deploy-intro/">Learn</a> more about kubernetes.</li>
            </ol>

            <h5>Limits</h5>
            <p>The default <a href="https://kubernetes.io/docs/tasks/configure-pod-container/assign-memory-resource/#specify-a-memory-request-and-a-memory-limit">Memory limit</a> per container for most namespaces is 4Gi. You can increase it for a container if needed.</p>

            <h5>Running GPU PODs</h5>
            <p>Use the <a href="https://github.com/dimm0/prp_k8s_config/blob/master/tensorflow-example.yaml">tensorflow example POD</a> definition to create your own pod and deploy it to kubernetes.</p>
            <p>You can try running this example in your namespace with:
              <div><code>kubectl create -f https://raw.githubusercontent.com/dimm0/prp_k8s_config/master/tensorflow-example.yaml</code></div>
            <br/>
            <p>and destroy with</p>
            <div><code>kubectl delete -f https://raw.githubusercontent.com/dimm0/prp_k8s_config/master/tensorflow-example.yaml</code></div><br/>
            This example requests 1 GPU device. You can have up to 8 per node.
            Currently we have 4 nodes set up for GPUs:
            <ul>
              <li><a href="https://grafana.k8s.optiputer.net/dashboard/db/cuda-gpu?var-node=67.58.53.155:9114">k8s-gpu-01.calit2.optiputer.net</a></li>
              <li><a href="https://grafana.k8s.optiputer.net/dashboard/db/cuda-gpu?var-node=67.58.53.156:9114">k8s-gpu-02.calit2.optiputer.net</a></li>
              <li><a href="https://grafana.k8s.optiputer.net/dashboard/db/cuda-gpu?var-node=198.17.101.69:9114">k8s-gpu-03.sdsc.optiputer.net</a></li>
              <li><a href="https://grafana.k8s.optiputer.net/dashboard/db/cuda-gpu?var-node=192.5.19.133:9114">fiona8.calit2.uci.edu</a></li>
            </ul>
            If you request GPU devices in your POD, kubernetes will auto schedule your pod to the appropriate node. There's no need to specify location manually.
            <br/><br/>
            <h5>Attaching Ceph blockdevice</h5>
            <p>Use the <a href="https://github.com/dimm0/prp_k8s_config/blob/master/volume-example.yaml">volume example POD</a> definition to create your own pod with <a href="https://grafana.k8s.optiputer.net/dashboard/db/rook-ceph">Rook block volume</a> attached.</p>
            <p><a href="https://github.com/rook/rook/blob/master/Documentation/k8s-filesystem.md">Shared filesystem</a> is also supported.</p>
          </div>
        </div>
      </div>
  </div>
  {{end}}
{{end}}

{{define "page_css"}}
<style type="text/css">
  code {
      word-wrap: break-word;
  }
</style>
{{end}}
